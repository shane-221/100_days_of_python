{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Lego Analysis for Course (start).ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "dc": {
          "key": "1d0b086e6c"
        },
        "run_control": {
          "frozen": true
        },
        "tags": [
          "context"
        ],
        "id": "s9JLDE8NIquP"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "Today we'll dive deep into a dataset all about LEGO. From the dataset we can ask whole bunch of interesting questions about the history of the LEGO company, their product offering, and which LEGO set ultimately rules them all:\n",
        "\n",
        "<ul type=\"square\">\n",
        "<li>What is the most enormous LEGO set ever created and how many parts did it have?</li>\n",
        "\n",
        "<li>How did the LEGO company start out? In which year were the first LEGO sets released and how many sets did the company sell when it first launched?</li>\n",
        "\n",
        "<li>Which LEGO theme has the most sets? Is it one of LEGO's own themes like Ninjago or a theme they licensed liked Harry Potter or Marvel Superheroes?</li>\n",
        "\n",
        "<li>When did the LEGO company really expand its product offering? Can we spot a change in the company strategy based on how many themes and sets did it released year-on-year?</li>\n",
        "\n",
        "<li>Did LEGO sets grow in size and complexity over time? Do older LEGO\n",
        "sets tend to have more or fewer parts than newer sets?</li>\n",
        "</ul>\n",
        "\n",
        "**Data Source**\n",
        "\n",
        "[Rebrickable](https://rebrickable.com/downloads/) has compiled data on all the LEGO pieces in existence. I recommend you use download the .csv files provided in this lesson."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0u2lGJuIquQ"
      },
      "source": [
        "# Import Statements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5Wk7rs-IquQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "05b6c62c-50cf-479b-b6d1-d1ce9953c52a"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/shane-221/100_days_of_python/refs/heads/main/74_Day_74_Aggregate_data/data/colors.csv\"\n",
        "dataset1= pd.read_csv(url, names =[\"ID\", \"Name\", \"RGB\", \"is_trans\"], header=0)\n",
        "\n",
        "# Summary Statistics\n",
        "dataset1.columns\n",
        "dataset1.head()\n",
        "dataset1.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "HTTP Error 404: Not Found",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1747065393.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://raw.githubusercontent.com/shane-221/100_days_of_python/refs/heads/main/74_Day_74_Aggregate_data/data/colors.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdataset1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ID\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"is_trans\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Summary Statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m     \u001b[0;31m# open URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m     ioargs = _get_filepath_or_buffer(\n\u001b[0m\u001b[1;32m    729\u001b[0m         \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# assuming storage_options is to be interpreted as headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mreq_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq_info\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m             \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Content-Encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gzip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    631\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5NQpJ_KIquT"
      },
      "source": [
        "# Data Exploration\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2><dir>Challenge 1<dir></h2>"
      ],
      "metadata": {
        "id": "3b3mTQgZCjw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Finds the unique set of names within the colour Column\n",
        "dataset1[\"Name\"].nunique(dropna=True)"
      ],
      "metadata": {
        "id": "OkqAsjIbCjjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "dc": {
          "key": "a5723ae5c2"
        },
        "run_control": {
          "frozen": true
        },
        "tags": [
          "context"
        ],
        "id": "PItRbqgcIqua"
      },
      "source": [
        "<h2><dir>Challenge 2<dir></h2>Find the number of transparent colours where <code>is_trans == 't'</code> versus the number of opaque colours where <code>is_trans == 'f'</code>. See if you can accomplish this in two different ways."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UZrfq82Iqub"
      },
      "source": [
        "# Find ing the number of transparent colours from dataset. One way to do this:\n",
        "dataset1[dataset1[\"is_trans\"]==\"t\"].count()\n",
        "dataset1[dataset1[\"is_trans\"]==\"f\"].count()\n",
        "\n",
        "# Another way to do this:\n",
        "dataset1.groupby(\"is_trans\")[[\"ID\"]].count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMqdhUYcusfy"
      },
      "source": [
        "\n",
        "<h2><dir>Challenge 3<dir></h2> Change this into an h3 section heading: Understanding LEGO Themes vs. LEGO Sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0kxCh63uwOv"
      },
      "source": [
        "Walk into a LEGO store and you will see their products organised by theme. Their themes include Star Wars, Batman, Harry Potter and many more.\n",
        "\n",
        "**Challenge**: Display this image: https://i.imgur.com/aKcwkSx.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "dc": {
          "key": "c9d0e58653"
        },
        "run_control": {
          "frozen": true
        },
        "tags": [
          "context"
        ],
        "id": "u_xkZUF8Iqug"
      },
      "source": [
        "A lego set is a particular box of LEGO or product. Therefore, a single theme typically has many different sets.\n",
        "\n",
        "**Challenge**: Display this image https://i.imgur.com/whB1olq.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJTAROe5unkx"
      },
      "source": [
        "The <code>sets.csv</code> data contains a list of sets over the years and the number of parts that each of these sets contained.\n",
        "\n",
        "**Challenge**: Read the sets.csv data and take a look at the first and last couple of rows."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<h1><b>Understanding LEGO Themes vs LEGO Sets</b></h1>\n",
        "<h3>Walk into a LEGO store and you will see their products organised by theme. Their themes include Star Wars, Batman, Harry Potter and many more.</h3>\n",
        "<img src= \"https://i.imgur.com/aKcwkSx.png\">\n",
        "\n",
        "<h3>A lego <b>set</b> is a particular box of LEGO or product. Therefore, a single theme typically has many different sets.</h3>\n",
        "\n",
        "<img src=\"https://i.imgur.com/whB1olq.png\">\n"
      ],
      "metadata": {
        "id": "QuqZGFesDIv6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<h2><div>Challeng 4<div></h2> Read the sets.csv data and take a look at the first and last couple of rows.\n",
        "\n",
        "The <code>sets.csv</code> data contains a list of sets over the years and the number of parts that each of these sets contained."
      ],
      "metadata": {
        "id": "ptyQwpFdDQ9i"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGMOv-NRIquh"
      },
      "source": [
        "url2= \"https://raw.githubusercontent.com/shane-221/100_days_of_python/refs/heads/main/74_Day_74_Aggregate_data/data/sets.csv\"\n",
        "\n",
        "# Getting the data\n",
        "dataset2 =pd.read_csv(url2)\n",
        "# the first few values\n",
        "dataset2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the last few values\n",
        "dataset2.tail()"
      ],
      "metadata": {
        "id": "j6fSjyZSDXtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ez-UXSMUIqum"
      },
      "source": [
        "<h2><dir>Challenge 5<dir></h2>\n",
        "In which year were the first LEGO sets released and what were these sets called?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2aL6qrGIqum"
      },
      "source": [
        "# Type is a number so no need to convert into datetime module\n",
        "print(type(dataset2[\"year\"][1]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Geeting the earliest date to point to the first set of lego being released.\n",
        "earliest_date =dataset2[\"year\"].min()\n",
        "row_value_earliest = dataset2[dataset2[\"year\"]==earliest_date]\n",
        "name_of_earliest_set= row_value_earliest[\"name\"]\n",
        "print(name_of_earliest_set)\n",
        "\n",
        "\n",
        "# Or you could use the sort function where it automatically sorts by ascending order\n",
        "dataset2.sort_values(\"year\").head()"
      ],
      "metadata": {
        "id": "g105qA21Dmcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJoK3M8TBAVU"
      },
      "source": [
        "<h2><dir>Challenge 6<dir></h2>\n",
        "How many different sets did LEGO sell in their first year? How many types of LEGO products were on offer in the year the company started?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-Tf1w7IBBg9"
      },
      "source": [
        "# How many differnt sets of LEGO did they sell in the first year?\n",
        "dataset2[dataset2[\"year\"]==earliest_date].nunique()[[\"set_num\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJMMYQYqIquo"
      },
      "source": [
        "<h2><dir>Challenge 7<dir></h2>\n",
        "Find the top 5 LEGO sets with the most number of parts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toJvjRuQIqup"
      },
      "source": [
        "# Number of Lego sets with the most number of parts\n",
        "dataset2.sort_values(\"num_parts\", ascending=False).head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSyhOzAHIqur"
      },
      "source": [
        "<h2><dir>Challenge 8 <dir></h2>\n",
        "Use <code>.groupby()</code> and <code>.count()</code> to show the number of LEGO sets released year-on-year. How do the number of sets released in 1955 compare to the number of sets released in 2019?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "qjdrktZAIqus"
      },
      "source": [
        "# Group by the sets released per year\n",
        "dataset3 = dataset2.groupby(\"year\").nunique()\n",
        "print(dataset3)\n",
        "dataset4= dataset3.reset_index()\n",
        "print(dataset4)\n",
        "\n",
        "# Could use a pivot table if there are two categorical values to match corrrectly."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJrmIOULIquv"
      },
      "source": [
        "<h2><dir>Challenge 9 <dir></h2>\n",
        "\n",
        "Show the number of LEGO releases on a line chart using Matplotlib. <br>\n",
        "\n",
        "<br>\n",
        "Note that the .csv file is from late 2020, so to plot the full calendar years, you will have to exclude some data from your chart. Can you use the slicing techniques covered in Day 21 to avoid plotting the last two years? The same syntax will work on Pandas DataFrames."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nckj4lSGIquw"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# setting the shape of the graph\n",
        "plt.figure(figsize= (16, 10))\n",
        "\n",
        "# fontsize for x and y values:\n",
        "plt.xticks(fontsize=14, rotation =90)\n",
        "plt.yticks(fontsize= 14)\n",
        "\n",
        "# Plotting the table plot( what goes in the x , what goes in the y , colour)\n",
        "plt.plot(dataset3.index[:-2], dataset3.set_num[:-2], \"b\")\n",
        "\n",
        "      # Remeber when you list slice it--- Needs to be from the index values and not the assigned groupings\n",
        "\n",
        "# Add lablels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZqAN-5MIquz"
      },
      "source": [
        "# Another way to do it:\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# setting the shape of the graph\n",
        "plt.figure(figsize= (16, 10))\n",
        "\n",
        "# fontsize for x and y values:\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize= 14)\n",
        "\n",
        "# Plotting the table plot( what goes in the x , what goes in the y , colour)\n",
        "plt.plot(dataset4[\"year\"][:-2], dataset3[\"set_num\"][:-2], \"b\")\n",
        "\n",
        "      # Remeber when you list slice it--- Needs to be from the index values and not the assigned groupings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Data Analysis</h1>\n",
        "<hr>"
      ],
      "metadata": {
        "id": "kh6ofxmoEOUq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrDeNYYXIqu1"
      },
      "source": [
        "### Aggregate Data with the Python .agg() Function\n",
        "\n",
        "Let's work out the number of different themes shipped by year. This means we have to count the number of unique theme_ids per calendar year."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2><dir>Challenge 1<dir></h2>\n",
        "Aggregate Data with the Python .agg() Function Let's work out the number of different themes shipped by year. This means we have to count the number of unique theme_ids per calendar year."
      ],
      "metadata": {
        "id": "kx14DdmjEUtP"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "dc": {
          "key": "266a3f390c"
        },
        "tags": [
          "sample_code"
        ],
        "id": "qx8pTau4Iqu2"
      },
      "source": [
        "themes_dataset= dataset2.groupby(\"year\").agg({\"theme_id\": pd.Series.nunique})\n",
        "                                                      # PD is the module, series represents the vector, and n uqnieu is the function all cases within a dicutionaly so the format always stays the same.\n",
        "                                                      # need to also state the nature of the aggregation\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the name of the column\n",
        "themes_dataset.rename (columns = {\"theme_id\":\"nr_themes\"}, inplace = True)\n",
        "print(themes_dataset)"
      ],
      "metadata": {
        "id": "dpjyZZx1Ell2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "immCqqw1Iqu5"
      },
      "source": [
        "<h2><dir>Challenge 2<dir></h2> Plot the number of themes released by year on a line chart. Only include the full calendar years (i.e., exclude 2020 and 2021)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2pamQEkIqu5"
      },
      "source": [
        "          # Size of the puicture\n",
        "plt.figure(figsize=(16,10))\n",
        "\n",
        "           # Size of the fonts\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "\n",
        "           # Labels\n",
        "plt.xlabel(\"Year\", fontsize=14)\n",
        "plt.ylabel(\"Number of Themes\", fontsize=14)\n",
        "\n",
        "          # The digaram itself: if you only have two things, no need to spcity which is the x and which is the Y\n",
        "plt.plot(themes_dataset[:-3], \"g\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBbt9-lJIqu7"
      },
      "source": [
        "<h2><dir>Challenge 3<dir></h2>\n",
        "Line Charts with Two Seperate Axes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7lQ_amFIqu7"
      },
      "source": [
        "# Good to have towo axis with two diffent sets of inputs and scale.\n",
        "\n",
        "\n",
        "  # one of the axis should represent the current axis\n",
        "ax1 = plt.gca()\n",
        "  # Set up another set of axis that shares the same x axis :\n",
        "ax2 = ax1.twinx()\n",
        "\n",
        "  # Plotting both of them:\n",
        "\n",
        "ax1.plot(dataset3.index[:-2],dataset3[\"set_num\"][:-2], \"b\")\n",
        "ax2.plot(dataset3.index[:-2], dataset3[\"theme_id\"][:-2], \"g\")\n",
        "\n",
        "\n",
        "  # Setting the labels.\n",
        "ax1.set_xlabel(\"Year\", fontsize= 14)\n",
        "ax1.set_xlabel(\"Year\", fontsize=14)\n",
        "ax2.set_ylabel(\"Number of themes\", fontsize =14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BHYaUf-Iqu9"
      },
      "source": [
        "<h2><dir>Challenge<dir></h2>\n",
        "Use the <code>.groupby()</code> and <code>.agg()</code> function together to figure out the average number of parts per set. How many parts did the average LEGO set released in 1954 compared to say, 2017?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7BcH9vuIqu9"
      },
      "source": [
        "# Group them by year\n",
        "parts_dataset = dataset3.groupby(\"year\").agg({\"num_parts\":pd.Series.sum, \"set_num\":pd.Series.sum})\n",
        "parts_dataset[\"parts_per_set_per_year\"] = parts_dataset[\"num_parts\"]/parts_dataset[\"set_num\"]\n",
        "    # Wehn you do group by need to apply a function to it to aggreagte all the results.\n",
        "\n",
        "# Difference in the average between 2017 and 1954\n",
        "value_2017 = parts_dataset.loc[2017, \"parts_per_set_per_year\"]\n",
        "value_1954 = parts_dataset.loc[1954, \"parts_per_set_per_year\"]\n",
        "answer= value_2017-value_1954\n",
        "print(answer)\n",
        "parts_dataset.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjbb3tZcIqu_"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAeTe2XqIqvB"
      },
      "source": [
        "### Scatter Plots in Matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAViZ_TYIqvB"
      },
      "source": [
        "**Challenge**: Has the size and complexity of LEGO sets increased over time based on the number of parts? Plot the average number of parts over time using a Matplotlib scatter plot. See if you can use the [scatter plot documentation](https://matplotlib.org/3.1.0/api/_as_gen/matplotlib.pyplot.scatter.html) before I show you the solution. Do you spot a trend in the chart?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQNZ0D7JIqvB"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xK226Ip-IqvE"
      },
      "source": [
        "### Number of Sets per LEGO Theme"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKHa1FePIqvE"
      },
      "source": [
        "LEGO has licensed many hit franchises from Harry Potter to Marvel Super Heros to many others. But which theme has the largest number of individual sets?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOBcNrC9IqvE"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-i6JULGIqvG"
      },
      "source": [
        "**Challenge** Use what you know about HTML markup and tags to display the database schema: https://i.imgur.com/Sg4lcjx.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27oDwiPHIqvH"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_0iuerKIqvG"
      },
      "source": [
        "### Database Schemas, Foreign Keys and Merging DataFrames\n",
        "\n",
        "The themes.csv file has the actual theme names. The sets .csv has <code>theme_ids</code> which link to the <code>id</code> column in the themes.csv."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cp1tMW6oIqvH"
      },
      "source": [
        "**Challenge**: Explore the themes.csv. How is it structured? Search for the name 'Star Wars'. How many <code>id</code>s correspond to this name in the themes.csv? Now use these <code>id</code>s and find the corresponding the sets in the sets.csv (Hint: you'll need to look for matches in the <code>theme_id</code> column)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uN3wN5sIqvH"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAO2XlQGIqvJ"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYEDlY-_IqvL"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "qBhckawNIqvN"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "aqt07DSTIqvP"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmTCXWKKIqvQ"
      },
      "source": [
        "### Merging (i.e., Combining) DataFrames based on a Key\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esKQULhcIqvR"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0LobgIvIqvT"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7UMP7VXIqvU"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}